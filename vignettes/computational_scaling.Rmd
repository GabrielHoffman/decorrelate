---
title: "Computational scaling of eclairs data whitening"
subtitle: 'Estimate of covariance using low rank and shrinkage'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Computational scaling of data whitening}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---



<!--- 

cd /hpc/users/hoffmg01/build2/decorrelate/vignettes
ml git pandoc

R
system("git pull")
rmarkdown::render("computational_scaling.Rmd");



system('cp /hpc/users/hoffmg01/build2/decorrelate/vignettes/computational_scaling.html ~/www/software/decorrelate/')

https://hoffmg01.u.hpc.mssm.edu/software/decorrelate/computational_scaling.html

--->



```{r setup, include=FALSE}
library(data.table)
library(lubridate)
library(tidyverse)
library(knitr)
library(kableExtra)

knitr::opts_chunk$set(
	eval = TRUE,
  echo = FALSE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  cache = TRUE)
```

```{r define.function}
eval_runTime = function(df_values){
	df_time = lapply( 1:nrow(df_values), function(i){

		n = df_values$n[i]
		p = df_values$p[i]
		k = df_values$k[i]

		message("\r", p, '       ')

		Y = matrnorm(n,p)
		zstat = rnorm(p)

		lambda <- 1e-1

		# full SVD
		res_decor = system.time({
			ecl <- eclairs(Y, compute="covariance", lambda=lambda)
			Z1 <- decorrelate(Y, ecl)
		})
		time_decorrelate = res_decor[3]

		# partial SVD
		res_partial = system.time({
			ecl <- eclairs(Y, compute="covariance", lambda=lambda, k=k)
			Z1 <- decorrelate(Y, ecl)
		})
		time_decorrelate_partial = res_partial[3]

		# naive
		if(p <= 20000){
			res2 = system.time({
				# C <- cov(Y) 
				# Sigma <- C*(1-lambda) + diag(lambda*ecl$nu, p)
				W = whiteningMatrix(cov(Y)*(1-lambda) + diag(lambda*ecl$nu, p), method="ZCA")
				Z2 <- tcrossprod(Y, W)
				# Z2 = whiten(Y)
			})
			time_naive = res2[3]

			# Z1 and Z2 are identical to machine precision
			# range(Z1 - Z2)

		}else{
			time_naive = NA
		}

		data.frame(n = n, p = p, k = k, 
			decorrelate = time_decorrelate, 
			"low rank" = time_decorrelate_partial,
			naive = time_naive)
	})
	df_time = do.call(rbind, df_time)
	df_time
}

fit_curves = function( df_time, curves ){
	# predict based on curves
	fit1 = lm(curves[[1]], df_time)
	fit2 = lm(curves[[2]], df_time)
	fit3 = lm(curves[[3]], df_time)

	p_max = max(df_time$p)
	n_max = max(df_time$n)

	df_p = data.table(p=seq(100, p_max, length.out=1000),
										n=seq(100, n_max, length.out=1000))

	df_p$decorrelate = predict(fit1, df_p)
	df_p$naive = predict(fit2, df_p)
	df_p$low.rank = predict(fit3, df_p)
	df_melt_p = melt(df_p, id.vars=c('p', 'n') )
	df_melt_p$variable = factor(df_melt_p$variable, c("naive", "decorrelate", 'low.rank'))

	# directly observed times
	df_melt = reshape2::melt(df_time, id.vars=c("p", 'n', 'k'))
	df_melt$variable = factor(df_melt$variable, c("naive", "decorrelate", 'low.rank'))

	list(df_observed = df_melt, df_smoothed = df_melt_p)
}
```

```{r simulate.data}
library(decorrelate)
library(Matrix)
library(Rfast)
library(ggplot2)
library(cowplot)
library(whitening)

# due to parallel processing, curves are not exactly cubic and linear
values = as.integer(sort(c(	seq(500, 20000, length.out=50), 
			seq(25000, 150000, length.out=50),
			seq(200000, 1000000, length.out=10))))

# values = as.integer(sort(c(	seq(100, 2000, length.out=10))))

df_values = data.frame(n = 500, p = values, k = 30)

df_time = eval_runTime( df_values )

curves = c(decorrelate ~ 0 + p,
	naive ~ 0 + I(p^3),
	low.rank ~ 0 + p)

res = fit_curves( df_time, curves)
```


```{r plot.results, cache=FALSE, fig.height=6, fig.width=12}
fig = ggplot(res$df_observed, aes(p, value, color=variable)) + geom_point() + theme_bw(16) + theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + xlab("Number of features") + ylab("Time in seconds") + geom_line(data=res$df_smoothed, aes(p, value, color=variable)) + scale_color_manual(name="Method", values = c("red", "blue", "green")) 

fig1 = fig + xlim(0, 20000) + ylim(0, max(df_time$naive, na.rm=TRUE))
fig2 = fig + ylim(0, max(df_time$naive, na.rm=TRUE))
fig3 = fig + scale_x_log10() + scale_y_log10()

plot_grid(fig1, fig2, fig3, nrow=1)
```


<!-- Run time at r max(values) features: -->

```{r time.table, cache=FALSE}
df2 = df_melt_p[p %in% c(2000, 1000000),]
df2$RunTime = seconds_to_period( round(df2$value, 0))

df2 %>% rename(Method = variable) %>% 
	select(Method,p, RunTime) %>% 
	kable(caption="Compare run times") %>% kable_styling(full_width=FALSE) 
```

<!-- 
This is a speed up of r format(max(df2$value) / min(df2$value), big.mark=',')

-->




# Increasing sample size


```{r increase.n}
values = as.integer(sort(c(	seq(100, 5000, length.out=20))))

df_values = data.frame(n = values, p=5000, k = 30)

df_time = eval_runTime( df_values )

curves = c(decorrelate ~ 0 + n,
	naive ~ 0 + I(n^2),
	low.rank ~ 0 + n)

res = fit_curves( df_time, curves)
```


```{r plot.results, cache=FALSE, fig.height=6, fig.width=12}
fig = ggplot(res$df_observed, aes(n, value, color=variable)) + geom_point() + theme_bw(16) + theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5), legend.position="bottom") + xlab("Number of samples") + ylab("Time in seconds") + geom_line(data=res$df_smoothed, aes(n, value, color=variable)) + scale_color_manual(name="Method", values = c("red", "blue", "green")) 

fig1 = fig + xlim(0, 20000) + ylim(0, max(df_time$naive, na.rm=TRUE))
fig2 = fig + ylim(0, max(df_time$naive, na.rm=TRUE))
fig3 = fig + scale_x_log10() + scale_y_log10()

plot_grid(fig1, fig2, fig3, nrow=1)
```






















