[{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"basic-usage","dir":"Articles","previous_headings":"","what":"Basic usage","title":"Fast Whitening Transformation","text":"plot ) eigen-values covariance matrix shrinkage. B) correlation observed C) whitened data.","code":"library(decorrelate) library(Rfast)  n <- 500  # number of samples p <- 200  # number of features  # create correlation matrix Sigma <- autocorr.mat(p, 0.9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", 1:n) colnames(Y) <- paste0(\"gene_\", 1:p)  # eclairs decomposition implements GIW-EB method: *E*stimate # *c*ovariance/correlation with *l*ow *r*ank and *s*hrinkage ecl <- eclairs(Y)  # decorrelate data using eclairs decomposition Y_whitened <- decorrelate(Y, ecl)  # the same whitening can be performed with one command where the eigen-value # shrinkage is performed internally Y_whitened2 <- whiten(Y) oldpar <- par(mfrow = c(1, 3))  # plot shrinkage of eigen-values plot(ecl)  # correlation between variables in observed data image(cor(Y), axes = FALSE, main = \"Correlation of observed data\")  # decorrelate data using eclairs decomposition image(cor(Y_whitened), axes = FALSE, main = \"Correlation of whitened data\") par(oldpar)"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"advanced-usage","dir":"Articles","previous_headings":"","what":"Advanced usage","title":"Fast Whitening Transformation","text":"decorrelate package advanced features examine details whitening transformation.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"directly-compute-whitening-matrix","dir":"Articles","previous_headings":"Advanced usage","what":"Directly compute whitening matrix","title":"Fast Whitening Transformation","text":"eclairs(), decorrelate(), whiten() perform probabilistic whitening transformation efficiently without directly computing whitening matrix, getWhiteningMatrix() can directly compute matrix. difference function due machine precision.","code":"# compute whitening matrix from eclairs decomposition W <- getWhiteningMatrix(ecl)  # transform observed data using whitening matrix Z <- tcrossprod(Y, W)  # evalute difference between whitened computed 2 ways max(abs(Z - Y_whitened)) ## [1] 4.085621e-14"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"explicit-covariance-or-correlation","dir":"Articles","previous_headings":"Advanced usage","what":"Explicit covariance or correlation","title":"Fast Whitening Transformation","text":"full covariance correlation matrix implied eclairs() decomposition can computed explicitly. Note computing storing matries O(p^2), may feasable large datasets.","code":"# compute correlation matrix from eclairs getCor(ecl)  # compute covariance matrix from eclairs getCov(ecl)"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"sample-from-multivariate-normal","dir":"Articles","previous_headings":"Advanced usage","what":"Sample from multivariate normal","title":"Fast Whitening Transformation","text":"form eclairs() decomposition can used efficiently sample multivariage normal distribution specified covariance.","code":"# draw from multivariate normal n <- 1000 mu <- rep(0, ncol(Y))  # using eclairs decomposition X.draw1 <- rmvnorm_eclairs(n, mu, ecl)"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"low-rank-models","dir":"Articles","previous_headings":"Advanced usage","what":"Low-rank models","title":"Fast Whitening Transformation","text":"low rank eclairs() decomposition can computed efficiently k small relative min(n,p). Importantly, emprical Bayes estimate shrinkage parameter \\lambda can still computed accurately sufficiently large k. Note low rank method trades computational efficientcy accuracy whitening transform.  case, low rank whitening produces transformed features approximately independent. approximation improves rank increases.","code":"# use low rank decomposition with 50 components ecl <- eclairs(Y, k = 60)  # decorrelate data using eclairs decomposition Y_whitened <- decorrelate(Y, ecl)"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"computing-condition-number","dir":"Articles","previous_headings":"Advanced usage","what":"Computing condition number","title":"Fast Whitening Transformation","text":"Compute condition number (.e. ratio largest smallest eigen-value) correlation/covariance matrix eclairs() decomposition.","code":"kappa(ecl) ## [1] 658.3446"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"removing-correlation-vs-covariance","dir":"Articles","previous_headings":"Advanced usage","what":"Removing correlation vs covariance","title":"Fast Whitening Transformation","text":"default eclairs() computes covariance columns using default compute = \"covariance\". Running decorrelate() using removes covariance columns. Setting compute = \"correlation\", evaluates removes correlation columns retaining variance.","code":"library(clusterGeneration)  # generate covariance matrix, where the diagonals (i.e. variances) vary Sigma <- genPositiveDefMat(p, rangeVar = c(1, 1e+06))$Sigma  Y <- rmvnorm(n, rep(0, p), sigma = Sigma)  # examine variances of the first 5 variables apply(Y, 2, var)[1:5] ## [1] 5.082884 2.853566 1.083664 3.687911 1.491565 # transform removes covariance between columns so variance of transformed # features are *approximately* equal ecl_cov <- eclairs(Y, compute = \"covariance\") Z1 <- decorrelate(Y, ecl_cov)  # variance are *approximately* equal apply(Z1, 2, var)[1:5] ## [1] 0.9830960 0.9939579 0.9924317 0.9939929 0.9945367 # transform removes **correlation** between columns but variables are not # scaled ecl_cor <- eclairs(Y, compute = \"correlation\") Z2 <- decorrelate(Y, ecl_cor)  # variances are not standardized apply(Z2, 2, var)[1:5] ## [1] 5.012871 2.830468 1.066778 3.661699 1.476049"},{"path":"http://gabrielhoffman.github.io/decorrelate/articles/decorrelate.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Fast Whitening Transformation","text":"","code":"## R version 4.3.0 (2023-04-21) ## Platform: x86_64-apple-darwin22.4.0 (64-bit) ## Running under: macOS Ventura 13.5 ##  ## Matrix products: default ## BLAS:   /Users/gabrielhoffman/prog/R-4.3.0/lib/libRblas.dylib  ## LAPACK: /usr/local/Cellar/r/4.3.0_1/lib/R/lib/libRlapack.dylib;  LAPACK version 3.11.0 ##  ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ##  ## time zone: America/New_York ## tzcode source: internal ##  ## attached base packages: ## [1] stats     graphics  grDevices utils     datasets  methods   base      ##  ## other attached packages: ## [1] clusterGeneration_1.3.7 MASS_7.3-60             latex2exp_0.9.6         ## [4] colorRamps_2.3.1        cowplot_1.1.1           ggplot2_3.4.2           ## [7] mvtnorm_1.2-2           decorrelate_0.0.18      ##  ## loaded via a namespace (and not attached): ##  [1] generics_0.1.3     sass_0.4.6         utf8_1.2.3         stringi_1.7.12     ##  [5] lattice_0.21-8     digest_0.6.33      magrittr_2.0.3     evaluate_0.21      ##  [9] grid_4.3.0         fastmap_1.1.1      rprojroot_2.0.3    jsonlite_1.8.5     ## [13] Matrix_1.5-4.1     formatR_1.14       purrr_1.0.1        fansi_1.0.4        ## [17] scales_1.2.1       codetools_0.2-19   textshaping_0.3.6  jquerylib_0.1.4    ## [21] Rdpack_2.4         cli_3.6.1          rlang_1.1.1        rbibutils_2.2.13   ## [25] munsell_0.5.0      withr_2.5.0        CholWishart_1.1.2  cachem_1.0.8       ## [29] yaml_2.3.7         tools_4.3.0        parallel_4.3.0     memoise_2.0.1      ## [33] dplyr_1.1.2        corpcor_1.6.10     colorspace_2.1-0   Rfast_2.0.7        ## [37] RcppZiggurat_0.1.6 vctrs_0.6.3        R6_2.5.1           lifecycle_1.0.3    ## [41] stringr_1.5.0      fs_1.6.2           ragg_1.2.5         irlba_2.3.5.1      ## [45] pkgconfig_2.0.3    desc_1.4.2         pkgdown_2.0.7      bslib_0.4.2        ## [49] pillar_1.9.0       gtable_0.3.3       glue_1.6.2         Rcpp_1.0.11        ## [53] whitening_1.4.0    systemfonts_1.0.4  highr_0.10         tidyselect_1.2.0   ## [57] xfun_0.39          tibble_3.2.1       knitr_1.43         farver_2.1.1       ## [61] htmltools_0.5.5    labeling_0.4.2     rmarkdown_2.22     compiler_4.3.0"},{"path":"http://gabrielhoffman.github.io/decorrelate/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gabriel Hoffman. Author, maintainer.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hoffman G (2025). decorrelate: Decorrelation Projection Scalable High Dimensional Data. R package version 0.1.7, https://gabrielhoffman.github.io/decorrelate/.","code":"@Manual{,   title = {decorrelate: Decorrelation Projection Scalable to High Dimensional Data},   author = {Gabriel Hoffman},   year = {2025},   note = {R package version 0.1.7},   url = {https://gabrielhoffman.github.io/decorrelate/}, }"},{"path":"http://gabrielhoffman.github.io/decorrelate/index.html","id":"fast-probabilistic-whitening-transformation-for-ultra-high-dimensional-data","dir":"","previous_headings":"","what":"Fast Probabilistic Whitening Transformation for Ultra-High Dimensional Data","title":"Decorrelation Projection Scalable to High Dimensional Data","text":"Data whitening widely used preprocessing step remove correlation structure since statistical models often assume independence (Kessy, et al. 2018). typical procedures transforms observed data inverse square root sample correlation matrix (Figure 1). low dimension data (.e. n > p), transformation produces transformed data identity sample covariance matrix. procedure assumes either true covariance matrix know, well estimated sample covariance matrix. Yet use sample covariance matrix transformation can problematic since 1) complexity \\mathcal{O}(p^3) 2) applicable high dimensional (.e. n \\ll p) case since sample covariance matrix longer full rank. use probabilistic model observed data apply whitening transformation. Gaussian Inverse Wishart Empirical Bayes (GIW-EB) 1) model substantially reduces computational complexity, 2) regularizes eigen-values sample covariance matrix improve --sample performance. Figure 1: Intuition data whitening transformation. ) Original data, B) Data rotated along principal components, C) Data rotated scaled, D) Data rotated, scaled rotated back original axes. Green arrows indicate principal axes lengths indicate eigen-values.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Decorrelation Projection Scalable to High Dimensional Data","text":"","code":"devtools::install_github(\"GabrielHoffman/decorrelate\")"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/autocorr.mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Create auto-correlation matrix — autocorr.mat","title":"Create auto-correlation matrix — autocorr.mat","text":"Create auto-correlation matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/autocorr.mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create auto-correlation matrix — autocorr.mat","text":"","code":"autocorr.mat(p, rho)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/autocorr.mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create auto-correlation matrix — autocorr.mat","text":"p dimension matrix rho autocorrelation value","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/autocorr.mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create auto-correlation matrix — autocorr.mat","text":"auto-matrix size p parameter rho","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/autocorr.mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create auto-correlation matrix — autocorr.mat","text":"","code":"# Create 4x4 matrix with correlation between adjacent enties is 0.9 autocorr.mat(4, .9) #>       [,1] [,2] [,3]  [,4] #> [1,] 1.000 0.90 0.81 0.729 #> [2,] 0.900 1.00 0.90 0.810 #> [3,] 0.810 0.90 1.00 0.900 #> [4,] 0.729 0.81 0.90 1.000"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/averageCorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute average correlation of implied correlation matrix — averageCorr","title":"Compute average correlation of implied correlation matrix — averageCorr","text":"Compute average correlation implied correlation matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/averageCorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute average correlation of implied correlation matrix — averageCorr","text":"","code":"averageCorr(   Sigma.eclairs,   method = c(\"MLE\", \"EB\"),   algorithm = c(\"closedApprox\", \"lossFxn\") )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/averageCorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute average correlation of implied correlation matrix — averageCorr","text":"Sigma.eclairs estimate correlation matrix eclairs() storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) method compute average correlation either MLE correlation matrix, empirical Bayes (EB) correlation matrix algorithm \"closedApprox\" uses closed form approximation works well large \\(n\\). \"lossFxn\" uses optimizes quadratic loss function observed eigen-values evalues constant correlation matrix.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/averageCorr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute average correlation of implied correlation matrix — averageCorr","text":"Consider correlation matrix \\(C\\) correlations set \\(\\rho\\), \\(d^2\\) vector eigen-values \\(C\\).  first eigen-value \\(1+(p-1)\\rho\\), next \\(p-1\\) eigen-values \\(1-\\rho\\).  (See https://statisticaloddsandends.wordpress.com/2018/07/20/ clear explanation.)  Now consider \\(C\\) sample correlation matrix, estimate average correlation based eigen-values.  case, additional eigen-values zero \\(p > n\\). Consider estimating \\(\\rho\\) using eigen-value separately. first eigen-value gives estimate \\((d^2_1 - 1) / (p-1)\\), next \\(p-1\\) eigen-values give estimate \\(1 - d^2_i\\), remaining estimates 0.  Finally, take mean single estimates final estimate \\(\\rho\\).  gives average correlation MLE correlation matrix. Since empirical Bayes estimate convex combination MLE identity matrix, average correlation EB correlation matrix \\((1-\\lambda)\\rho\\)","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/averageCorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute average correlation of implied correlation matrix — averageCorr","text":"","code":"library(Rfast) #> Loading required package: Rcpp #> Loading required package: RcppZiggurat set.seed(1) n = 200 # number of samples p = 800 # number of features  # create correlation matrix Sigma = matrix(.2, p, p) diag(Sigma) = 1  # draw data from correlation matrix Sigma Y = rmvnorm(n, rep(0, p), sigma=Sigma) rownames(Y) = paste0(\"sample_\", 1:n) colnames(Y) = paste0(\"gene_\", 1:p)  # eclairs decomposition Sigma.eclairs = eclairs(Y, compute=\"cor\")  averageCorr( Sigma.eclairs ) #> [1] 0.2222902"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cca.html","id":null,"dir":"Reference","previous_headings":"","what":"Canonical correlation analysis — cca","title":"Canonical correlation analysis — cca","text":"Canonical correlation analysis scalable high dimensional data.  Uses covariance shrinkage algorithmic speed ups linear time p p > n.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Canonical correlation analysis — cca","text":"","code":"cca(X, Y, k = min(dim(X), dim(Y)), lambda.x = NULL, lambda.y = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Canonical correlation analysis — cca","text":"X first matrix (n x p1) Y first matrix (n x p2) k number canonical components return lambda.x optional shrinkage parameter estimating covariance X. NULL, estimate data. lambda.y optional shrinkage parameter estimating covariance Y. NULL, estimate data.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Canonical correlation analysis — cca","text":"statistics summarizing CCA","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Canonical correlation analysis — cca","text":"Results standard CCA based SVD \\(\\Sigma_{xx}^{-\\frac{1}{2}} \\Sigma_{xy} \\Sigma_{yy}^{-\\frac{1}{2}}\\). Avoids computation \\(\\Sigma_{xx}^{-\\frac{1}{2}}\\) using eclairs.  Avoids cov(X,Y) framing matrix product can distributed. Uses low rank SVD. regularized CCA adds lambda covariance like Ridge. mixture","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate covariance matrix after applying transformation — cov_transform","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"Given covariance features original data, estimate covariance matrix applying transformation feature.  use eclairs decomposition original covariance matrix, perform parametric bootstrap return eclairs decomposition covariance matrix transformed data.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"","code":"cov_transform(   ecl,   f,   n.boot,   lambda = NULL,   compute = c(\"covariance\", \"correlation\"),   seed = NULL )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"ecl covariance/correlation matrix eclairs object f function specifying transformation. n.boot number parametric bootstrap samples.  Increasing n gives precise estimates. lambda shrinkage parameter.  specified, estimated data. compute evaluate either \"covariance\" \"correlation\" X seed want generated use seed generator, integer number","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"eclairs decomposition representing correlation/covariance transformed data","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"transformation linear, covariance matrices .","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/cov_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate covariance matrix after applying transformation — cov_transform","text":"","code":"library(Rfast) #> Loading required package: Rcpp #> Loading required package: zigg #> Loading required package: RcppParallel #>  #> Attaching package: ‘RcppParallel’ #> The following object is masked from ‘package:Rcpp’: #>  #>     LdFlags #>  #> Rfast: 2.1.5.1 #>  ___ __ __ __ __    __ __ __ __ __ _             _               __ __ __ __ __     __ __ __ __ __ __    #> |  __ __ __ __  |  |  __ __ __ __ _/            / \\             |  __ __ __ __ /   /__ __ _   _ __ __\\   #> | |           | |  | |                         / _ \\            | |                        / /           #> | |           | |  | |                        / / \\ \\           | |                       / /           #> | |           | |  | |                       / /   \\ \\          | |                      / /           #> | |__ __ __ __| |  | |__ __ __ __           / /     \\ \\         | |__ __ __ __ _        / /__/\\           #> |    __ __ __ __|  |  __ __ __ __|         / /__ _ __\\ \\        |_ __ __ __ _   |      / ___  /            #> |   \\              | |                    / _ _ _ _ _ _ \\                     | |      \\/  / /        #> | |\\ \\             | |                   / /           \\ \\                    | |         / /           #> | | \\ \\            | |                  / /             \\ \\                   | |        / /           #> | |  \\ \\           | |                 / /               \\ \\                  | |       / /           #> | |   \\ \\__ __ _   | |                / /                 \\ \\     _ __ __ __ _| |      / /           #> |_|    \\__ __ __\\  |_|               /_/                   \\_\\   /_ __ __ __ ___|      \\/             team  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # sample matrix from MVN with covariance Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma, seed = 1)  # perform eclairs decomposition ecl <- eclairs(Y)  # Parametric boostrap to estimate covariance # after transformation  # transformation function f <- function(x) log(x^2 + 1e-3)  # number of bootstrap samples n_boot <- 5000  # Evaluate eclairs decomposition on boostrap samples ecl2 <- cov_transform(ecl, f = f, n_boot, lambda = 1e-4)  # Get full covariance matrix from eclairs decomposition C1 <- getCov(ecl2)  # Parametric boostrap samples directly from full covariance matrix X <- rmvnorm(n_boot, rep(0, p), getCov(ecl))  # get covariance of transformed data C2 <- cov(f(X))  # Evaluate differences # small differences are due to Monte Carlo error from boostrap sampling range(C1 - C2) #> [1] -0.3269305  0.2868029  # Plot entries from two covariance estimates par(pty = \"s\") plot(C1, C2, main = \"Concordance between covariances\") abline(0, 1, col = \"red\")   # Same above but compute eclairs for correlation matrix #-------------------------------------------------------  # Evaluate eclairs decomposition on boostrap samples ecl2 <- cov_transform(ecl, f = f, n_boot, compute = \"correlation\", lambda = 1e-4)  # Get full covariance matrix from eclairs decomposition C1 <- getCor(ecl2)  # Parametric boostrap samples directly from full covariance matrix X <- rmvnorm(n_boot, rep(0, p), getCov(ecl))  # get correlation of transformed data C2 <- cor(f(X))  # Evaluate differences # small differences are due to Monte Carlo error from boostrap sampling range(C1 - C2) #> [1] -0.08475414  0.09047862  # Plot entries from two correlation estimates oldpar <- par(pty = \"s\") plot(C1, C2, main = \"Correlation between covariances\") abline(0, 1, col = \"red\")   par(oldpar)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":null,"dir":"Reference","previous_headings":"","what":"Decorrelation projection — decorrelate","title":"Decorrelation projection — decorrelate","text":"Efficient decorrelation projection using eclairs decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decorrelation projection — decorrelate","text":"","code":"decorrelate(X, ecl, lambda, transpose = FALSE, alpha = -1/2)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decorrelation projection — decorrelate","text":"X matrix transformed *columns* independent ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) lambda specify lambda override value ecl transpose logical, (default FALSE) indicating X transposed first alpha default = -1/2.  Exponent eigen-values","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decorrelation projection — decorrelate","text":"matrix following decorrelation transformation","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decorrelation projection — decorrelate","text":"Apply decorrelation transform using implicit covariance approach avoid directly evaluating covariance matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/decorrelate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decorrelation projection — decorrelate","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # whitened Y Y.transform <- decorrelate(Y, ecl) #"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply by diagonal matrix — dmult","title":"Multiply by diagonal matrix — dmult","text":"Multiply diagonal matrix using efficient algorithm","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply by diagonal matrix — dmult","text":"","code":"dmult(M, v, side = c(\"left\", \"right\"))"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply by diagonal matrix — dmult","text":"M matrix v vector entries forming diagonal matrix matching dimensions M depending value side side matrix M \"left\" \"right\" multiplied diagonal matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiply by diagonal matrix — dmult","text":"matrix product","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiply by diagonal matrix — dmult","text":"Naively multiplying diagonal matrix p entries takes \\(\\mathcal{O}(p^2)\\), even though must values diagonal matrix zero.  R built syntax scale columns, diag(v) %*% M can evaluated v * M.  often difficult remember, hard look , scaling rows requires t(t(M) * v).  hard read write, requires two transpose operations. , dmult() uses Rcpp evaluate right multiplication efficiently, uses v * M left multiplication.  gives good performance readability. principle, Rcpp code can modified use BLAS better performance treating NumericMatrix C array.  currently bottleneck","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/dmult.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiply by diagonal matrix — dmult","text":"","code":"# right multiply # mat %*% diag(v) n <- 30 p <- 20 mat <- matrix(n * p, n, p) v <- rnorm(p)  A <- dmult(mat, v, side = \"right\") B <- mat %*% diag(v) range(A - B) #> [1] 0 0  # left multiply # diag(v) %*% mat n <- 30 p <- 20 mat <- matrix(n * p, p, n) v <- rnorm(p)  A <- dmult(mat, v, side = \"left\") B <- diag(v) %*% mat range(A - B) #> [1] 0 0"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class eclairs — eclairs-class","title":"Class eclairs — eclairs-class","text":"Class eclairs","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class eclairs — eclairs-class","text":"Object storing: U: orthonormal matrix k columns representing low rank component dSq: eigen-values \\(U diag(d^2) U^T\\) low rank component lambda: shrinkage parameter \\(\\lambda\\) scaled diagonal component sigma: standard deviations input columns nu: diagonal value, \\(\\nu\\), target matrix shrinkage n: number samples (.e. rows) original data p: number features (.e. columns) original data k: rank low rank component rownames: sample names original matrix colnames: features names original matrix method: method used decomposition call: function call","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate covariance/correlation with low rank and shrinkage — eclairs","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"Estimate covariance/correlation columns weighted sum low rank matrix scaled identity matrix.  weight acts shrink sample correlation matrix towards identity matrix sample covariance matrix towards scaled identity matrix constant variance.  estimate form useful fast, enables fast operations downstream.  method based Gaussian Inverse Wishart Empirical Bayes (GIW-EB) model.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"","code":"eclairs(   X,   k = min(n, p),   lambda = NULL,   compute = c(\"covariance\", \"correlation\"),   n.samples = nrow(X),   svd.method = c(\"svd\", \"irlba\", \"pcaone\") )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"X data matrix n samples rows p features columns k rank low rank component lambda shrinkage parameter. specified, estimated data. compute evaluate either \"covariance\" \"correlation\" X n.samples number samples data .  Usually nrow(X), can values special cases. svd.method SVD algorithm string \"svd\", \"irlba\", \"pcaone\"","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"eclairs object storing: U: orthonormal matrix k columns representing low rank component dSq: eigen-values \\(U diag(d^2) U^T\\) low rank component lambda: shrinkage parameter \\(\\lambda\\) scaled diagonal component sigma: standard deviations input columns nu: diagonal value, \\(\\nu\\), target matrix shrinkage n: number samples (.e. rows) original data p: number features (.e. columns) original data k: rank low rank component rownames: sample names original matrix colnames: features names original matrix method: method used decomposition call: function call","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"Compute \\(U\\), \\(d^2\\) approximate correlation matrix columns data matrix X \\(U diag(d^2 (1-\\lambda)) U^T + \\nu\\lambda\\).  computing covariance matrix, scale standard deviation feature.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition: covariance ecl <- eclairs(Y, compute = \"covariance\")  ecl #>        Estimate covariance with low rank and shrinkage #>  #>   Original data dims: 800 x 200  #>   Low rank component: 200  #>   lambda:             0.0265  #>   nu:                 1  #>   sd(200):            2.21 2.22 ... 2.18 #>   logLik:             -117651  #>   Method:             svd   # eclairs decomposition: correlation ecl <- eclairs(Y, compute = \"correlation\")  ecl #>        Estimate correlation with low rank and shrinkage #>  #>   Original data dims: 800 x 200  #>   Low rank component: 200  #>   lambda:             0.0265  #>   nu:                 1  #>   Avg corr (EB):      0.0832  #>   Avg corrSq (EB):    0.0402  #>   logLik:             -117651  #>   Method:             svd"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_corMat.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","text":"Estimate covariance/correlation low rank shrinkage correlation matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_corMat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","text":"","code":"eclairs_corMat(C, n, k = min(n, nrow(C)), lambda = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_corMat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","text":"C sample correlation matrix features n number samples used estimate sample correlation matrix k rank low rank component.  Defaults min sample size feature number, min(n, p). lambda shrinkage parameter. specified, estimated data.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_corMat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","text":"eclairs object storing: U: orthonormal matrix k columns representing low rank component dSq: eigen-values \\(U diag(d^2) U^T\\) low rank component lambda: shrinkage parameter \\(\\lambda\\) scaled diagonal component sigma: standard deviations input columns nu: diagonal value, \\(\\nu\\), target matrix shrinkage n: number samples (.e. rows) original data p: number features (.e. columns) original data k: rank low rank component rownames: sample names original matrix colnames: features names original matrix method: method used decomposition call: function call","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_corMat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate covariance/correlation with low rank and shrinkage — eclairs_corMat","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", 1:n) colnames(Y) <- paste0(\"gene_\", 1:p)  # eclairs decomposition eclairs(Y, compute = \"correlation\") #>        Estimate correlation with low rank and shrinkage #>  #>   Original data dims: 800 x 200  #>   Low rank component: 200  #>   lambda:             0.0265  #>   nu:                 1  #>   Avg corr (EB):      0.0832  #>   Avg corrSq (EB):    0.0402  #>   logLik:             -117651  #>   Method:             svd   # eclairs decomposition from correlation matrix eclairs_corMat(cor(Y), n = n) #>        Estimate correlation with low rank and shrinkage #>  #>   Original data dims: 800 x 200  #>   Low rank component: 200  #>   lambda:             0.0265  #>   nu:                 1  #>   Avg corr (EB):      0.0832  #>   Avg corrSq (EB):    0.0402  #>   logLik:             -117651  #>   Method:             eigen"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"Given eclairs decomp C, compute eclairs decomp C^2","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"","code":"eclairs_sq(ecl, rank1 = ecl$k, rank2 = Inf, varianceFraction = 1)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"ecl estimate correlation matrix eclairs() storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) rank1 use first 'rank' singular vectors SVD.  Using increasing rank1 increase accuracy estimation.  note computationaly complexity O(P choose(rank, 2)), P number features dataset rank2 rank eclairs() decomposition returned varianceFraction fraction variance retain truncating trailing eigen values","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"compute eclairs C^2","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"Consider data matrix \\(X_{N x P}\\) \\(P\\) features \\(N\\) samples \\(N << P\\). Let columns X scaled \\(C_{P x P} = XX^T\\).  C often big compute directly since O(P^2) O(P^3) invert.  can compute SVD X O(PN^2). goal compute SVD matrix C^2, given SVD C less \\(O(P^2)\\) time.  compute SVD C^2 \\(O(PN^4)\\) time, tractible small N. Moreover, use SVD X = UDV^T rank R, can approximate SVD C^2 O(PR^4) using D V","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/eclairs_sq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute eclairs decomp of squared correlation matrix — eclairs_sq","text":"","code":"# Compute correlations directly and using eclairs decomp  n <- 600 # number of samples p <- 100 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- Rfast::rmvnorm(n, rep(0, p), sigma = Sigma, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # correlation computed directly C <- cor(Y)  # correlation from eclairs decomposition ecl <- eclairs(Y, compute = \"cor\") C.eclairs <- getCor(ecl, lambda = 0)  all.equal(C, C.eclairs) #> [1] TRUE  # Correlation of Y^2 #-------------------  # exact quadratic way C <- 2 * cor(Y)^2  # faster low rank ecl2 <- eclairs_sq(ecl) C.eclairs <- 2 * getCor(ecl2, lambda = 0)  all.equal(C.eclairs, C) #> [1] TRUE"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"Estimate shrinkage parameter empirical Bayes","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"","code":"estimate_lambda_eb(ev, n, p, nu, lambda = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"ev array eigen values n number samples p number features nu scale prior covariance matrix lambda (default: NULL) NULL, estimate lambda data. Else evaluate logML using specified lambda value.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"value \\(\\lambda\\) indicating shrinkage sample prior covariance matrices.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"Estimate shrinkage parameter covariance matrix estimation using empirical Bayes method (Leday Richardson 2019; Hannart Naveau 2014) .  shrinage estimate covariance matrix \\((1-\\lambda)\\hat\\Sigma + \\lambda \\nu \\), \\(\\hat\\Sigma\\) sample covariance matrix, given value \\(\\lambda\\).  large value \\(\\lambda\\) indicates weight prior.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"Hannart , Naveau P (2014). “Estimating high dimensional covariance matrices: new look Gaussian conjugate framework.” Journal Multivariate Analysis, 131, 149--162. Leday GG, Richardson S (2019). “Fast Bayesian inference large Gaussian graphical models.” Biometrics, 75(4), 1288--1298.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/estimate_lambda_eb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate shrinkage parameter by empirical Bayes — estimate_lambda_eb","text":"","code":"ev <- c(10, 2, 1) # eigen values n <- 12 # samples p <- 3 # features nu <- 2 # scale of target covariance  estimate_lambda_eb(ev, n, p, nu) #> $lambda #> [1] 0.03382545 #>  #> $logML #> [1] -30.95033 #>"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca-class.html","id":null,"dir":"Reference","previous_headings":"","what":"Class fastcca — fastcca-class","title":"Class fastcca — fastcca-class","text":"Class fastcca","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca-class.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Class fastcca — fastcca-class","text":"Object storing: n.comp: number canonical components cors: canonical correlations x.coefs: canonical coefficients X x.vars: canonical variates X y.coefs: canonical coefficients Y y.vars: canonical variates Y lambdas: shrinkage parameters eclairs","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast canonical correlation analysis — fastcca","title":"Fast canonical correlation analysis — fastcca","text":"Fast Canonical correlation analysis scalable high dimensional data.  Uses covariance shrinkage algorithmic speed ups linear time p p > n.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast canonical correlation analysis — fastcca","text":"","code":"fastcca(X, Y, k = min(dim(X), dim(Y)), lambda.x = NULL, lambda.y = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast canonical correlation analysis — fastcca","text":"X first matrix (n x p1) Y first matrix (n x p2) k number canonical components return lambda.x optional shrinkage parameter estimating covariance X. NULL, estimate data. lambda.y optional shrinkage parameter estimating covariance Y. NULL, estimate data.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast canonical correlation analysis — fastcca","text":"fastcca object","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fast canonical correlation analysis — fastcca","text":"summary statistics CCA Results standard CCA based SVD \\(\\Sigma_{xx}^{-\\frac{1}{2}} \\Sigma_{xy} \\Sigma_{yy}^{-\\frac{1}{2}}\\). Uses eclairs() empirical Bayes covariance regularization, applies speed RCCA (Tuzhilina, et al. 2023) perform CCA n PCs instead p features.  Memory usage \\(\\mathcal{O}(np)\\) instead \\(\\mathcal{O}(p^2)\\).  Computation \\(\\mathcal{O}(n^2p)\\) instead \\(\\mathcal{O}(p^3)\\) \\(\\mathcal{O}(np^2)\\)","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fast canonical correlation analysis — fastcca","text":"Tuzhilina, E., Tozzi, L., & Hastie, T. (2023). Canonical correlation analysis high dimensions structured regularization. Statistical modelling, 23(3), 203-227.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca2.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast canonical correlation analysis — fastcca2","title":"Fast canonical correlation analysis — fastcca2","text":"Fast Canonical correlation analysis scalable high dimensional data.  Uses covariance shrinkage algorithmic speed ups linear time p p > n.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast canonical correlation analysis — fastcca2","text":"","code":"fastcca2(   X,   Y,   k = NULL,   k.x = min(dim(X)),   k.y = min(dim(Y)),   lambda.x = NULL,   lambda.y = NULL,   svd.method = c(\"svd\", \"irlba\", \"pcaone\") )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast canonical correlation analysis — fastcca2","text":"X first matrix (n x p1) Y first matrix (n x p2) k number canonical components return lambda.x optional shrinkage parameter estimating covariance X. NULL, estimate data. lambda.y optional shrinkage parameter estimating covariance Y. NULL, estimate data.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/fastcca2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fast canonical correlation analysis — fastcca2","text":"","code":"pop <- LifeCycleSavings[, 2:3] oec <- LifeCycleSavings[, -(2:3)]  fastcca2(pop, oec) #>        Fast regularized canonical correlation analysis #>  #>   Original data rows: 50  #>   Original data cols: 2, 3 #>   Num components:     2  #>   rho.mod:            0.865 0.314 ... #>   Cramer's V:         0.65  #>   lambda:             0.0123 0.6647"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":null,"dir":"Reference","previous_headings":"","what":"Get full covariance/correlation matrix from eclairs — getCov","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"Get full covariance/correlation matrix eclairs decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"","code":"getCov(ecl, lambda, ...)  getCor(ecl, lambda, ...)  # S4 method for class 'eclairs' getCov(ecl, lambda, ...)  # S4 method for class 'eclairs' getCor(ecl, lambda, ...)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"ecl eclairs decomposition lambda shrinkage parameter convex combination. ... arguments","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"p x p covariance/correlation matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"full matrix computationally expensive compute uses lot memory large p.  better use decorrelate mult_eclairs perform projections \\(O(np)\\) time.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getCov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get full covariance/correlation matrix from eclairs — getCov","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition ecl <- eclairs(Y)  # extract covariance implied by eclairs decomposition getCov(ecl)[1:3, 1:3] #>          gene_1   gene_2   gene_3 #> gene_1 4.897772 4.333904 3.887720 #> gene_2 4.333904 4.916274 4.257193 #> gene_3 3.887720 4.257193 4.927556"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"Estimate shrinkage parameter empirical Bayes","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"","code":"getShrinkageParams(ecl, k = ecl$k, minimum = 1e-04, lambda = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"ecl eclairs() decomposition k number singular vectors use minimum minimum value lambda lambda (default: NULL) NULL, estimate lambda data. Else evaluate logML using specified lambda value.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"value \\(\\lambda\\) \\(\\nu\\) indicating shrinkage sample prior covariance matrices.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"Estimate shrinkage parameter covariance matrix estimation using empirical Bayes method (Hannart Naveau, 2014; Leday Richardson 2019).  shrinage estimate covariance matrix \\((1-\\lambda)\\hat\\Sigma + \\lambda \\nu \\), \\(\\hat\\Sigma\\) sample covariance matrix, given value \\(\\lambda\\).  large value \\(\\lambda\\) indicates weight prior.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"Hannart, ., & Naveau, P. (2014). Estimating high dimensional covariance matrices: new look Gaussian conjugate framework. Journal Multivariate Analysis, 131, 149-162. Leday, G. G., & Richardson, S. (2019). Fast Bayesian inference large Gaussian graphical models. Biometrics, 75(4), 1288-1298.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getShrinkageParams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate shrinkage parameter by empirical Bayes — getShrinkageParams","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition: covariance ecl <- eclairs(Y, compute = \"correlation\")  # For full SVD getShrinkageParams(ecl) #>       lambda    logLik nu #> 1 0.02652135 -117651.2  1  # For truncated SVD at k = 20 getShrinkageParams(ecl, k = 20) #>      lambda    logLik       nu #> 1 0.4481936 -190888.6 1.250719"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getWhiteningMatrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Get whitening matrix — getWhiteningMatrix","title":"Get whitening matrix — getWhiteningMatrix","text":"Get whitening matrix implied eclairs decompostion","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getWhiteningMatrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get whitening matrix — getWhiteningMatrix","text":"","code":"getWhiteningMatrix(ecl, lambda)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getWhiteningMatrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get whitening matrix — getWhiteningMatrix","text":"ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) lambda specify lambda override value ecl","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getWhiteningMatrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get whitening matrix — getWhiteningMatrix","text":"whitening matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/getWhiteningMatrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get whitening matrix — getWhiteningMatrix","text":"","code":"library(Rfast)  n <- 2000 p <- 3  Y <- matrnorm(n, p, seed = 1) * 10  # decorrelate with implicit whitening matrix # give same result as explicity whitening matrix ecl <- eclairs(Y, compute = \"covariance\")  # get explicit whitening matrix W <- getWhiteningMatrix(ecl)  # apply explicit whitening matrix Z1 <- tcrossprod(Y, W)  # use implicit whitening matrix Z2 <- decorrelate(Y, ecl)  range(Z1 - Z2) #> [1] -8.881784e-16  1.332268e-15"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/kappa.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute condition number — kappa,eclairs-method","title":"Compute condition number — kappa,eclairs-method","text":"Compute condition number matrix eclairs decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/kappa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute condition number — kappa,eclairs-method","text":"","code":"# S4 method for class 'eclairs' kappa(z, lambda = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/kappa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute condition number — kappa,eclairs-method","text":"z eclairs() decomposition lambda specify lambda override value z","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/kappa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute condition number — kappa,eclairs-method","text":"condition number correlation matrix.  z covariance matrix, kappa computed correlation component","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/kappa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute condition number — kappa,eclairs-method","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition ecl <- eclairs(Y, compute = \"correlation\")  # compute condition number kappa(ecl) #> [1] 395.0645"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_each_eclairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit linear model on each feature after decorrelating — lm_each_eclairs","title":"Fit linear model on each feature after decorrelating — lm_each_eclairs","text":"Fit linear model feature applying decorrelation projection response predictors.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_each_eclairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit linear model on each feature after decorrelating — lm_each_eclairs","text":"","code":"lm_each_eclairs(   formula,   data,   X,   ecl,   subset,   weights,   na.action,   method = \"qr\",   model = TRUE,   x = FALSE,   y = FALSE,   qr = TRUE,   singular.ok = TRUE,   contrasts = NULL,   offset,   ... )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_each_eclairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit linear model on each feature after decorrelating — lm_each_eclairs","text":"formula object class 'formula' (one can coerced class): symbolic description model fitted. data matrix data.frame containing variables model X matrix data.frame column stores predictor evaluated regression model one time.  \\(^{th}\\) model includes X[,] predictor. ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) subset lm weights lm na.action lm method lm model lm x lm y lm qr lm singular.ok lm contrasts lm offset lm ... arguments passed lm()","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_each_eclairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit linear model on each feature after decorrelating — lm_each_eclairs","text":"data.frame columns beta, se, tsat, pvalue storing results regression model fit feature","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_each_eclairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit linear model on each feature after decorrelating — lm_each_eclairs","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # simulate covariates data <- data.frame(matrnorm(p, 2, seed = 1)) colnames(data) <- paste0(\"v\", 1:2)  # simulate response y <- rnorm(p)  # Simulate 1000 features to test X <- matrnorm(p, 1000, seed = 1) colnames(X) <- paste0(\"set_\", seq(ncol(X)))  # Use linear model to test each feature stored as columns in X res <- lm_each_eclairs(y ~ v1 + v2, data, X, ecl)  head(res) #>                beta           se       tstat     pvalue #> set_1 -1.650310e+13 1.656970e+14 -0.09959809 0.92076521 #> set_2  8.305168e+13 6.865661e+14  0.12096677 0.90384128 #> set_3  1.913700e-01 8.408944e-02  2.27579150 0.02393987 #> set_4 -5.504664e-02 9.314628e-02 -0.59096978 0.55522154 #> set_5  8.806717e-02 7.788111e-02  1.13078984 0.25952533 #> set_6  1.382841e-01 8.188201e-02  1.68882095 0.09284398  # Analysis after non-linear transform #------------------------------------  # Apply function to transforme data f <- function(x) log(x^2 + 0.001)  # evaluate covariance of transformed data ecl_transform <- cov_transform(ecl, f, 100)  # Use linear model to test each feature stored as columns in X # in data transformed by f() res2 <- lm_each_eclairs(f(y) ~ v1 + v2, data, X, ecl_transform)  head(res) #>                beta           se       tstat     pvalue #> set_1 -1.650310e+13 1.656970e+14 -0.09959809 0.92076521 #> set_2  8.305168e+13 6.865661e+14  0.12096677 0.90384128 #> set_3  1.913700e-01 8.408944e-02  2.27579150 0.02393987 #> set_4 -5.504664e-02 9.314628e-02 -0.59096978 0.55522154 #> set_5  8.806717e-02 7.788111e-02  1.13078984 0.25952533 #> set_6  1.382841e-01 8.188201e-02  1.68882095 0.09284398"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit linear model after decorrelating — lm_eclairs","title":"Fit linear model after decorrelating — lm_eclairs","text":"Fit linear model applying decorrelation projection response predictors.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit linear model after decorrelating — lm_eclairs","text":"","code":"lm_eclairs(   formula,   data,   ecl,   subset,   weights,   na.action,   method = \"qr\",   model = TRUE,   x = FALSE,   y = FALSE,   qr = TRUE,   singular.ok = TRUE,   contrasts = NULL,   offset,   ... )"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit linear model after decorrelating — lm_eclairs","text":"formula object class 'formula' (one can coerced class): symbolic description model fitted. data matrix data.frame containing variables model ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) subset lm weights lm na.action lm method lm model lm x lm y lm qr lm singular.ok lm contrasts lm offset lm ... lm","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit linear model after decorrelating — lm_eclairs","text":"Object class lm returned function lm","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit linear model after decorrelating — lm_eclairs","text":"function fit linear regression transformed response, transformed design matrix.  Note design matrix, just data.frame variables transformed 1) factors transformed 2) intercept term transformed.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/lm_eclairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit linear model after decorrelating — lm_eclairs","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # simulate covariates data <- data.frame(matrnorm(p, 2, seed = 1)) colnames(data) <- paste0(\"v\", 1:2)  # simulate response y <- rnorm(p)  # fit linear model on transformed data lm_eclairs(y ~ v1 + v2, data, ecl) #>  #> Call: #> lm_eclairs(formula = y ~ v1 + v2, data = data, ecl = ecl) #>  #> Coefficients: #> (Intercept)           v1           v2   #>     0.07776     -0.03798     -0.05242   #>"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/logDet.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the log determinant — logDet","title":"Evaluate the log determinant — logDet","text":"Evaluate log determinant matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/logDet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the log determinant — logDet","text":"","code":"logDet(ecl, alpha = 1)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/logDet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the log determinant — logDet","text":"ecl estimate covariance/correlation matrix eclairs() storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) alpha exponent applied eigen-values","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/logDet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the log determinant — logDet","text":"log determinant","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/logDet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the log determinant — logDet","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition ecl <- eclairs(Y)  logDet(ecl) #> [1] 16.44463"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":null,"dir":"Reference","previous_headings":"","what":"Mahalanobis Distance — mahalanobisDistance","title":"Mahalanobis Distance — mahalanobisDistance","text":"Mahalanobis Distance using eclairs() decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mahalanobis Distance — mahalanobisDistance","text":"","code":"mahalanobisDistance(ecl, X, lambda, center = FALSE)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mahalanobis Distance — mahalanobisDistance","text":"ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) X data matrix lambda specify lambda override value ‘ecl’ center logical: columns centered internally","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mahalanobis Distance — mahalanobisDistance","text":"array distances","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mahalanobis Distance — mahalanobisDistance","text":"Evaluate quadratic form \\((X-\\mu)^T \\Sigma^{-1} (X-\\mu)\\) covariance estimated finite sample","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mahalanobisDistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mahalanobis Distance — mahalanobisDistance","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # Mahalanobis distance after mean centering Y_center <- scale(Y, scale = FALSE) mu <- colMeans(Y)  # Standard R method a <- mahalanobis(Y, mu, cov = cov(Y))  # distance using eclairs decomposition, no shrinage b <- mahalanobisDistance(ecl, Y_center, lambda = 0) range(a - b) #> [1] -1.676881e-12  3.069545e-12  # with shrinkage d <- mahalanobisDistance(ecl, Y_center)  # centering internally e <- mahalanobisDistance(ecl, Y, center = TRUE) range(d - e) #> [1] 0 0 #"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mult_eclairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiply by eclairs matrix — mult_eclairs","title":"Multiply by eclairs matrix — mult_eclairs","text":"Multiply eclairs matrix using special structure achieve linear instead cubic time complexity.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mult_eclairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiply by eclairs matrix — mult_eclairs","text":"","code":"mult_eclairs(X, U1, dSq1, lambda, nu, alpha, sigma, transpose = FALSE)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mult_eclairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiply by eclairs matrix — mult_eclairs","text":"X matrix transformed *columns* independent U1 orthonormal matrix k columns representing low rank component dSq1 eigen values \\(U_1 diag(d_1^2) U_1^T\\) low rank component lambda shrinkage parameter convex combination. nu diagonal value target matrix shrinkage alpha exponent evaluated sigma standard deviation feature transpose logical, (default FALSE) indicating X transposed first","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mult_eclairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiply by eclairs matrix — mult_eclairs","text":"matrix product","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/mult_eclairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiply by eclairs matrix — mult_eclairs","text":"Let \\(\\Sigma = U_1 diag(d_1^2) U_1^T * (1-\\lambda) + diag(\\nu\\lambda, p)\\), \\(\\lambda\\) shrinkage parameter convex combination low rank matrix diagonal matrix values \\(\\nu\\). Evaluate \\(X \\Sigma^\\alpha\\) using special structure eclairs decomposition \\(O(k^2p)\\) \\(k\\) components decomposition.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/optimal_SVHT_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","title":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","text":"function calculation coefficient determining optimal location hard threshold matrix denoising singular values hard thresholding noise level known unknown. Recreation MATLAB code Matan Gavish David Donoho.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/optimal_SVHT_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","text":"","code":"optimal_SVHT_coef(beta, sigma_known = FALSE)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/optimal_SVHT_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","text":"beta single value vector represents aspect ratio m/n matrix denoised. 0<beta<=1. sigma_known logical value. TRUE noise level known, FALSE unknown.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/optimal_SVHT_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","text":"Optimal location hard threshold, median data singular value (sigma unknown) sigma*sqrt(n) (sigma known); vector dimension beta, coef[] coefficient corresponding beta[].","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/optimal_SVHT_coef.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Optimal Hard Threshold for Singular Values — optimal_SVHT_coef","text":"Gavish, M., & Donoho, D. L. (2014). optimal hard threshold singular values 4/sqrt(3). IEEE Transactions Information Theory, 60(8), 5040-5053.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/plot-eclairs-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot eclairs object — plot,eclairs-method","title":"Plot eclairs object — plot,eclairs-method","text":"Plot eclairs object","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/plot-eclairs-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot eclairs object — plot,eclairs-method","text":"","code":"# S4 method for class 'eclairs' plot(x, y, ...)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/plot-eclairs-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot eclairs object — plot,eclairs-method","text":"x eclairs object y extra argument, used ... additional arguments","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/plot-eclairs-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot eclairs object — plot,eclairs-method","text":"plot","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate quadratic form — quadForm","title":"Evaluate quadratic form — quadForm","text":"Evaluate quadratic form","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate quadratic form — quadForm","text":"","code":"quadForm(ecl, A, alpha = -1/2)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate quadratic form — quadForm","text":"ecl estimate covariance/correlation matrix eclairs storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) matrix alpha default = -1/2.  Exponent eigen-values","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate quadratic form — quadForm","text":"scalar value","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate quadratic form — quadForm","text":"Evaluate quadratic form \\(^T \\Sigma^{2\\alpha} \\)","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/quadForm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate quadratic form — quadForm","text":"","code":"library(Rfast) n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # return scalar quadForm(ecl, Y[1, ]) #> [1] 175.8736  # return matrix quadForm(ecl, Y[1:2, ]) #>           [,1]      [,2] #> [1,] 175.87358  11.73997 #> [2,]  11.73997 139.87274"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Recompute eclairs after dropping features — reform_decomp","title":"Recompute eclairs after dropping features — reform_decomp","text":"Recompute eclairs dropping features","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recompute eclairs after dropping features — reform_decomp","text":"","code":"reform_decomp(ecl, k = ecl$k, drop = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recompute eclairs after dropping features — reform_decomp","text":"ecl covariance/correlation matrix eclairs object k rank low rank component drop array variable names drop.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recompute eclairs after dropping features — reform_decomp","text":"eclairs decomposition subset features","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recompute eclairs after dropping features — reform_decomp","text":"Reform dataset eclairs decomposition, drop features, recompute eclairs decomposition.  original SVD/eigen truncated, reconstruction original data approximate.  Note target shrinkage matrix ecl, \\(\\nu\\) recomputed retained features.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/reform_decomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recompute eclairs after dropping features — reform_decomp","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # Correlation #------------  # eclairs decomposition Sigma.eclairs <- eclairs(Y, compute = \"correlation\")  # features to drop drop <- paste0(\"gene_\", 1:100)  # Compute SVD on subset of eclairs decomposition ecl1 <- reform_decomp(Sigma.eclairs, drop = drop)  ecl1 #>        Estimate correlation with low rank and shrinkage #>  #>   Original data dims: 800 x 100  #>   Low rank component: 100  #>   lambda:             0.0144  #>   nu:                 1  #>   Avg corr (EB):      0.16  #>   Avg corrSq (EB):    0.0807  #>   logLik:             -55420  #>   Method:             svd"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"Draw multivariate normal t distributions using eclairs decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"","code":"rmvnorm_eclairs(n, mu, ecl, v = Inf, seed = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"n sample size mu mean vector ecl covariance matrix eclairs object v degrees freedom, defaults Inf.  finite, uses multivariate t distribution seed want generated use seed generator, integer number","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"matrix rows samples multivariate normal t distribution columns covariance specified ecl","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"Draw multivariate normal t distributions using eclairs decomposition.  (implied) covariance matrix \\(p \\times p\\), standard approach \\(O(p^3)\\). Taking advantage previously computed eclairs decomposition rank \\(k\\), can done \\(O(pk^2)\\).","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/rmvnorm_eclairs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw from multivariate normal and t distributions — rmvnorm_eclairs","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma, seed = 1)  # perform eclairs decomposition ecl <- eclairs(Y)  # draw from multivariate normal n <- 10000 mu <- rep(0, ncol(Y))  # using eclairs decomposition X.draw1 <- rmvnorm_eclairs(n, mu, ecl)  # using full covariance matrix implied by eclairs model X.draw2 <- rmvnorm(n, mu, getCov(ecl))  # assess difference betweeen covariances from two methods range(cov(X.draw1) - cov(X.draw2)) #> [1] -0.07761519  0.08804192  # compare covariance to the covariance matrix used to simulated the data range(cov(X.draw1) - getCov(ecl)) #> [1] -0.05744341  0.06452279"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/run_svd.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute SVD with selected algorithm — run_svd","title":"Compute SVD with selected algorithm — run_svd","text":"Compute SVD using exact, approximate randomized algorithms","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/run_svd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute SVD with selected algorithm — run_svd","text":"","code":"run_svd(X, k = min(dim(X)), method = c(\"svd\", \"irlba\", \"pcaone\"), ...)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/run_svd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute SVD with selected algorithm — run_svd","text":"X data matrix k number left right singular values compute method SVD algorithm string \"svd\", \"irlba\", \"pcaone\" ... arguments passed SVD functions","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/run_svd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute SVD with selected algorithm — run_svd","text":"Compute SVD using select algorithm.  Let data matrix X n rows p columns.  min(n,p) singular vectors can computed. \"svd\": exact algorithm using standard svd() function.  Fastest choice computing greater min(n,p)/3 singular vectors. \"irlba\": approximate algorithm using implicitly restarted Lanczos bidiagonalization irlba::irlba().  Much faster \"svd\" computing less min(n,p)/3  singular vectors, matching svd() moderate precision \"pcaone\": randomized SVD algorithm implemented pcaone::pcaone().  Fastest method large datasets, computing min(n,p)/3  singular vectors.  Singular vectors values approximate can differ svd() percent.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/run_svd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute SVD with selected algorithm — run_svd","text":"","code":"hilbert <- function(n) { i <- 1:n; 1 / outer(i - 1, i, `+`) } X <- hilbert(9)[, 1:6] dcmp1 <- run_svd(X, method = \"svd\") dcmp2 <- run_svd(X, method = \"irlba\") dcmp3 <- run_svd(X, method = \"pcaone\")"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/series_start_total.html","id":null,"dir":"Reference","previous_headings":"","what":"Create decreasing series of values — series_start_total","title":"Create decreasing series of values — series_start_total","text":"Create series \\(n\\) values decreasing \\(start\\) constant ratio terms values sum \\(totalSum\\)","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/series_start_total.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create decreasing series of values — series_start_total","text":"","code":"series_start_total(start, totalSum, n)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/series_start_total.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create decreasing series of values — series_start_total","text":"start maximum value totalSum specify target sum values produces n number terms","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize correlation matrix — averageCorr","title":"Summarize correlation matrix — averageCorr","text":"Summarize correlation matrix scalar scalar value, given SVD shrinkage parameter. averageCorr() computes average correlation, averageCorrSq() computes average squared correlation, exclude diagonal terms. sumInverseCorr() computes sum entries inverse correlation matrix give 'effective number independent features'. effVariance() evaluates effective variance correlation (covariance) matrix.  values can computed using correlation matrix using standard MLE, EB shrinkage.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize correlation matrix — averageCorr","text":"","code":"averageCorr(ecl, method = c(\"EB\", \"MLE\"))  averageCorrSq(ecl, method = c(\"EB\", \"MLE\"))  sumInverseCorr(ecl, method = c(\"EB\", \"MLE\"), absolute = TRUE)  effVariance(ecl, method = c(\"EB\", \"MLE\"))  tr(ecl, method = c(\"EB\", \"MLE\"))"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize correlation matrix — averageCorr","text":"ecl estimate correlation matrix eclairs() storing \\(U\\), \\(d_1^2\\), \\(\\lambda\\) \\(\\nu\\) method compute average correlation either empirical Bayes (EB) shinken correlation matrix MLE correlation matrix absolute TRUE (default) evaluate absolute correlation matrix","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize correlation matrix — averageCorr","text":"value summary statistic","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize correlation matrix — averageCorr","text":"tr(): trace matrix. Sum diagonals sum eigen-values. averageCorr(): average correlation computed summing -diagonal values correlation matrix. sum elements matrix \\(g = \\sum_{,j} C_{,j} = 1^T C 1 \\), \\(1\\) vector \\(p\\) elements entries 1. last term quadratic form correlation matrix can computed efficiently using SVD shrinkage parameter eclairs().  Given value \\(g\\), average computed subtracting diagonal values dividing number -diagonal values: \\((g - p) / (p(p-1))\\). averageCorrSq(): average squared correlation computed using eigen-values. Surprisingly, function variance eigen-values.  reviewed Watanabe (2022) Durand Le Roux (2017).  Letting \\(\\lambda_i\\) \\(^{th}\\) sample shrunk eigen-value, \\(\\tilde{\\lambda}\\) mean eigen-value, \\(\\sum_i (\\lambda_i - \\tilde{\\lambda})^2 / p(p-1)\\tilde{\\lambda}^2\\). sumInverseCorr(): 'effective number independent features' computed summing entires inverse covariance matrix.  form \\(\\sum_{,j} C^{-1}_{,j} = 1^T C^{-1} 1\\). last term quadratic form correlation matrix can computed efficiently using SVD shrinkage parameter eclairs() described . effVariance(): Compute metric amount variation represented correlation (covariance) matrix comparable across matrices difference sizes. Proposed Peña Rodriguez (2003), 'effective variance' \\(|C|^\\frac{1}{p}\\) \\(C\\) correlation (covariance matrix) \\(p\\) variables. effective variance mean log eigen-values.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Summarize correlation matrix — averageCorr","text":"Durand, J. L., & Le Roux, B. (2017). Linkage index variables relationship variance eigenvalues PCA MCA. Statistica Applicata-Italian Journal Applied Statistics, (2-3), 123-135. Peña, D., & Rodriguez, J. (2003). Descriptive measures multivariate scatter linear dependence. Journal Multivariate Analysis, 85(2), 361-374. Watanabe, J. (2022). Statistics eigenvalue dispersion indices: Quantifying magnitude phenotypic integration. Evolution, 76(1), 4-28.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/summarizeCorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize correlation matrix — averageCorr","text":"","code":"library(Rfast) n <- 200 # number of samples p <- 800 # number of features  # create correlation matrix Sigma <- matrix(.2, p, p) diag(Sigma) <- 1  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma, seed = 1) rownames(Y) <- paste0(\"sample_\", seq(n)) colnames(Y) <- paste0(\"gene_\", seq(p))  # eclairs decomposition ecl <- eclairs(Y, compute = \"cor\")  # Average correlation value averageCorr(ecl) #> [1] 0.03586329  # Average squared correlation value averageCorrSq(ecl) #> [1] 0.001437541  # Sum elements in inverse correlation matrix # Gives the effective number of independent features sumInverseCorr(ecl) #> [1] 39.78366  # Effective variance effVariance(ecl) #> [1] 0.9336296"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Singular value thresholding — sv_threshold","title":"Singular value thresholding — sv_threshold","text":"Singular value thresholding evaluates optimal number singular values retain","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Singular value thresholding — sv_threshold","text":"","code":"sv_threshold(n, p, d)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Singular value thresholding — sv_threshold","text":"n number samples p number features d singular values","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Singular value thresholding — sv_threshold","text":"Number singular values retain","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Singular value thresholding — sv_threshold","text":"Gavish, M., & Donoho, D. L. (2014). optimal hard threshold singular values 4/sqrt(3). IEEE Transactions Information Theory, 60(8), 5040-5053.","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/sv_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Singular value thresholding — sv_threshold","text":"","code":"# simulate data  n <- 500 p <- 5000 Y <- Rfast::matrnorm(n, p, seed = 1)  # SVD dcmp <- svd(Y)  # how many components to retain sv_threshold(n, p, dcmp$d) #> [1] 0  # in this case the data has no structure, so no components are retained"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/whiten.html","id":null,"dir":"Reference","previous_headings":"","what":"Decorrelation projection + eclairs — whiten","title":"Decorrelation projection + eclairs — whiten","text":"Efficient decorrelation projection using eclairs decomposition","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/whiten.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decorrelation projection + eclairs — whiten","text":"","code":"whiten(X, k = ncol(X), lambda = NULL)"},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/whiten.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decorrelation projection + eclairs — whiten","text":"X matrix transformed *columns* independent k rank low rank component lambda specify lambda override value estimated eclairs()","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/whiten.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decorrelation projection + eclairs — whiten","text":"data rotated scaled according regularized sample covariance input data","code":""},{"path":"http://gabrielhoffman.github.io/decorrelate/reference/whiten.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decorrelation projection + eclairs — whiten","text":"","code":"library(Rfast)  n <- 800 # number of samples p <- 200 # number of features  # create correlation matrix Sigma <- autocorr.mat(p, .9)  # draw data from correlation matrix Sigma Y <- rmvnorm(n, rep(0, p), sigma = Sigma * 5.1, seed = 1)  # eclairs decomposition ecl <- eclairs(Y)  # whitened Y Y.transform <- decorrelate(Y, ecl)  # Combine eclairs and decorrelate into one step Y.transform2 <- whiten(Y)"}]
